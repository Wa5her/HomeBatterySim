{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## API call Functions\n",
    "This section handles all API calls to octopus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import requests\n",
    "import json\n",
    "\n",
    "\n",
    "\n",
    "# Your Octopus Energy API key\n",
    "\n",
    "\n",
    "# API_KEY = \"YOUR_API_KEY\"\n",
    "\n",
    "\n",
    "\n",
    "# Function to fetch electricity consumption data for a specific MPAN and meter serial number\n",
    "\n",
    "\n",
    "\n",
    "def get_electricity_consumption(mpan, meter_serial_number, period_from, period_to):\n",
    "\n",
    "\n",
    "    url = f\"https://api.octopus.energy/v1/electricity-meter-points/{mpan}/meters/{\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        meter_serial_number}/consumption?page_size=14000&period_from={period_from}&period_to={period_to}\"\n",
    "\n",
    "    response = requests.get(url, auth=(API_KEY, ''))\n",
    "\n",
    "    return response.json()\n",
    "\n",
    "\n",
    "\n",
    "# Function to fetch tariff prices for a specific product and tariff code\n",
    "\n",
    "\n",
    "\n",
    "def get_tariff_prices_old(tariff_code, period_from, period_to):\n",
    "    product_code = tariff_code[5:-2]\n",
    "\n",
    "    url = f\"https://api.octopus.energy/v1/products/{product_code}/electricity-tariffs/{\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        tariff_code}/standard-unit-rates?page_size=14000&period_from={period_from}&period_to={period_to}\"\n",
    "\n",
    "    # print(url)\n",
    "    response = requests.get(url, auth=(API_KEY, ''))\n",
    "\n",
    "    return response.json()\n",
    "\n",
    "\n",
    "def get_tariff_prices(tariff_code, period_from, period_to):\n",
    "    product_code = tariff_code[5:-2]\n",
    "    url = f\"https://api.octopus.energy/v1/products/{product_code}/electricity-tariffs/{\n",
    "        tariff_code}/standard-unit-rates?page_size=14000&period_from={period_from}&period_to={period_to}\"\n",
    "    response = requests.get(url, auth=(API_KEY, ''))\n",
    "    data = response.json()\n",
    "    all_data = data['results']\n",
    "\n",
    "    while data['next'] is not None:\n",
    "        # Get the next page URL\n",
    "        next_page_url = data['next']\n",
    "        response = requests.get(next_page_url, auth=(API_KEY, ''))\n",
    "        data = response.json()\n",
    "        all_data.extend(data['results'])\n",
    "\n",
    "    return all_data\n",
    "\n",
    "\n",
    "# Main function to gather consumption data and tariff costs\n",
    "\n",
    "\n",
    "\n",
    "def get_electricity_data(account_number, start_date, end_date):\n",
    "\n",
    "\n",
    "    # Get account details to get MPAN and meter information\n",
    "\n",
    "\n",
    "    account_url = f\"https://api.octopus.energy/v1/accounts/{account_number}/\"\n",
    "\n",
    "    account_response = requests.get(account_url, auth=(API_KEY, ''))\n",
    "\n",
    "    account_data = account_response.json()\n",
    "\n",
    "\n",
    "    # Extract MPAN and meter information\n",
    "\n",
    "    mpans = [meter_point['mpan']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "             for meter_point in account_data['properties'][0]['electricity_meter_points']]\n",
    "\n",
    "    meter_serial_numbers = [meter['serial_number']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                            for meter in account_data['properties'][0]['electricity_meter_points'][0]['meters']]\n",
    "    tariff_code = account_data['properties'][0]['electricity_meter_points'][0]['agreements'][0]['tariff_code']\n",
    "\n",
    "\n",
    "    # Fetch consumption data for each MPAN and meter\n",
    "\n",
    "    consumption_data = {}\n",
    "    mpan_file = open('mpan_meter.csv', 'w')\n",
    "\n",
    "    for mpan in mpans:\n",
    "\n",
    "        for meter_serial_number in meter_serial_numbers:\n",
    "\n",
    "            mpan_file.write(f'{mpan}-{meter_serial_number}\\n')\n",
    "\n",
    "            consumption_data[(mpan, meter_serial_number)] = get_electricity_consumption(\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                mpan, meter_serial_number, start_date, end_date)\n",
    "            with open(f'{mpan}-{meter_serial_number}.json', 'w') as f:\n",
    "                json.dump(consumption_data[(mpan, meter_serial_number)], f)\n",
    "\n",
    "    mpan_file.close()\n",
    "\n",
    "    # Fetch tariff prices for all tariffs associated with the account\n",
    "    tariff_file = open('tariffs.csv', 'w')\n",
    "\n",
    "    tariff_codes = [tariff['tariff_code'] for tariff in account_data['properties']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                    [0]['electricity_meter_points'][0]['agreements']]\n",
    "\n",
    "    tariff_prices = {}\n",
    "\n",
    "    for tariff_code in tariff_codes:\n",
    "        tariff_file.write(f'{tariff_code}\\n')\n",
    "\n",
    "        tariff_prices[tariff_code] = get_tariff_prices(\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            tariff_code, start_date, end_date)\n",
    "        with open(f'{tariff_code}.json', 'w') as f:\n",
    "            json.dump(tariff_prices[tariff_code], f)\n",
    "\n",
    "    tariff_file.close()\n",
    "\n",
    "    return {\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        \"consumption_data\": consumption_data,\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        \"tariff_prices\": tariff_prices\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## API calling execution\n",
    "This part is the actual execution to get tarrifs and consumption based on functions above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Usage example\n",
    "account_number = \"A-3FAEDC7D\"\n",
    "start_date = \"2024-04-19T01:00:00Z\"\n",
    "end_date = \"2025-01-27T00:00:00Z\"\n",
    "\n",
    "# load keys\n",
    "\n",
    "# get API key from file\n",
    "with open('apikey.txt', 'r') as file:\n",
    "    API_KEY = file.read()\n",
    "\n",
    "electricity_data = get_electricity_data(account_number, start_date, end_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download energy selling price in Agile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get export cost data\n",
    "export_data = get_tariff_prices(\n",
    "    'E-1R-AGILE-OUTGOING-BB-23-02-28-H', start_date, end_date)\n",
    "with open('export.json', 'w') as f:\n",
    "    json.dump(export_data, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run this section after each time the data gets downloaded to convert Jsons to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred: 0\n",
      "An error occurred: 0\n",
      "An error occurred: 0\n",
      "Successfully converted export.json to export.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import json\n",
    "import csv\n",
    "import os\n",
    "\n",
    "\n",
    "def json_to_csv(json_file_path, csv_file_path):\n",
    "    \"\"\"\n",
    "    Converts a JSON file to a CSV file.\n",
    "\n",
    "    Args:\n",
    "        json_file_path: Path to the JSON file.\n",
    "        csv_file_path: Path to the output CSV file.\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        with open(json_file_path, 'r') as f:\n",
    "            data = json.load(f)\n",
    "\n",
    "        results = data.get('results', [])  # Extract the 'results' list\n",
    "\n",
    "        if not results:\n",
    "            print(\"No 'results' found in the JSON file.\")\n",
    "            return\n",
    "\n",
    "        # Extract field names from the first dictionary in results\n",
    "        fieldnames = results[0].keys() if results else []\n",
    "\n",
    "        with open(csv_file_path, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "\n",
    "            writer.writeheader()  # Write the header row\n",
    "            writer.writerows(results)  # Write the data rows\n",
    "\n",
    "        print(f\"Successfully converted {json_file_path} to {csv_file_path}\")\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: JSON file not found at {json_file_path}\")\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"Error: Invalid JSON format in {json_file_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "\n",
    "# Get the current directory\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "for filename in os.listdir(current_dir):\n",
    "    # Check if the file is a JSON file\n",
    "    if filename.endswith(\".json\"):\n",
    "\n",
    "        # Construct the full file path\n",
    "        json_file_name = filename\n",
    "        # Define the output CSV file name based on the JSON file name\n",
    "        csv_file_name = json_file_name.replace(\".json\", \".csv\")\n",
    "        json_to_csv(json_file_name, csv_file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# breakpoint All files downloaded now. \n",
    "## Rest of this code is junk. Develop code to merge 3 CSV files - consumption, Buy rate, sell rate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "\n",
    "def merge_csv_files(tariffs_file=\"tariffs.csv\"):\n",
    "    \"\"\"\n",
    "    Merges CSV files listed in a tariffs file, adding a column indicating the source file.\n",
    "\n",
    "    Args:\n",
    "        tariffs_file (str, optional): Path to the tariffs CSV file. Defaults to \"tariffs.csv\".\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: Merged DataFrame with a 'source_file' column, or empty DataFrame on error.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        tariff_files_df = pd.read_csv(\n",
    "            tariffs_file, header=None, names=['filename'])\n",
    "        all_data = []\n",
    "\n",
    "        for filename in tariff_files_df['filename']:\n",
    "            filepath = f\"{filename}.csv\"\n",
    "            if os.path.exists(filepath):\n",
    "                try:\n",
    "                    df = pd.read_csv(filepath, parse_dates=True)\n",
    "                    # Add the source filename as a new column\n",
    "                    df['source_file'] = filename\n",
    "                    all_data.append(df)\n",
    "                except pd.errors.EmptyDataError:\n",
    "                    print(f\"Warning: File {filepath} is empty.\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Error reading {filepath}: {e}\")\n",
    "            else:\n",
    "                print(f\"Warning: File {filepath} not found.\")\n",
    "\n",
    "        if all_data:\n",
    "            merged_df = pd.concat(all_data, ignore_index=True)\n",
    "            return merged_df\n",
    "        else:\n",
    "            print(\"No CSV files could be read. Returning empty DataFrame.\")\n",
    "            return pd.DataFrame()\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Tariffs file '{tariffs_file}' not found.\")\n",
    "        return pd.DataFrame()\n",
    "    except pd.errors.EmptyDataError:\n",
    "        print(f\"Error: Tariffs file '{tariffs_file}' is empty.\")\n",
    "        return pd.DataFrame()\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "merged_tariffs = merge_csv_files('tariffs.csv')\n",
    "merged_kWh = merge_csv_files('mpan_meter.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>consumption</th>\n",
       "      <th>interval_start</th>\n",
       "      <th>interval_end</th>\n",
       "      <th>source_file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.287</td>\n",
       "      <td>2025-01-27T00:00:00Z</td>\n",
       "      <td>2025-01-27T00:30:00Z</td>\n",
       "      <td>2600002565617-22L4294637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.296</td>\n",
       "      <td>2025-01-26T23:30:00Z</td>\n",
       "      <td>2025-01-27T00:00:00Z</td>\n",
       "      <td>2600002565617-22L4294637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.445</td>\n",
       "      <td>2025-01-26T23:00:00Z</td>\n",
       "      <td>2025-01-26T23:30:00Z</td>\n",
       "      <td>2600002565617-22L4294637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.838</td>\n",
       "      <td>2025-01-26T22:30:00Z</td>\n",
       "      <td>2025-01-26T23:00:00Z</td>\n",
       "      <td>2600002565617-22L4294637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.426</td>\n",
       "      <td>2025-01-26T22:00:00Z</td>\n",
       "      <td>2025-01-26T22:30:00Z</td>\n",
       "      <td>2600002565617-22L4294637</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   consumption        interval_start          interval_end  \\\n",
       "0        0.287  2025-01-27T00:00:00Z  2025-01-27T00:30:00Z   \n",
       "1        0.296  2025-01-26T23:30:00Z  2025-01-27T00:00:00Z   \n",
       "2        0.445  2025-01-26T23:00:00Z  2025-01-26T23:30:00Z   \n",
       "3        0.838  2025-01-26T22:30:00Z  2025-01-26T23:00:00Z   \n",
       "4        0.426  2025-01-26T22:00:00Z  2025-01-26T22:30:00Z   \n",
       "\n",
       "                source_file  \n",
       "0  2600002565617-22L4294637  \n",
       "1  2600002565617-22L4294637  \n",
       "2  2600002565617-22L4294637  \n",
       "3  2600002565617-22L4294637  \n",
       "4  2600002565617-22L4294637  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merged_tariffs.head()\n",
    "merged_kWh.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 13583 entries, 0 to 13582\n",
      "Data columns (total 4 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   consumption     13583 non-null  float64\n",
      " 1   interval_start  13583 non-null  object \n",
      " 2   interval_end    13583 non-null  object \n",
      " 3   source_file     13583 non-null  object \n",
      "dtypes: float64(1), object(3)\n",
      "memory usage: 424.6+ KB\n"
     ]
    }
   ],
   "source": [
    "# This section looks up the price for each row in consumption\n",
    "merged_kWh['interval_start'] = pd.to_datetime(merged_kWh['interval_start'])\n",
    "merged_kWh['interval_end'] = pd.to_datetime(merged_kWh['interval_end'])\n",
    "merged_tariffs['valid_from'] = pd.to_datetime(merged_tariffs['valid_from'])\n",
    "merged_tariffs['valid_to'] = pd.to_datetime(merged_tariffs['valid_to'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'<=' not supported between instances of 'Timestamp' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 34\u001b[0m\n\u001b[0;32m     32\u001b[0m export_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexport.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, parse_dates\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalid_from\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalid_to\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     33\u001b[0m power_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrate\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m power_df\u001b[38;5;241m.\u001b[39mapply(get_rate, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 34\u001b[0m power_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrate_sale\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mpower_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mget_rate_sale\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32me:\\Eshwar\\Projects\\Home Battery\\.venv\\Lib\\site-packages\\pandas\\core\\frame.py:10374\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[1;34m(self, func, axis, raw, result_type, args, by_row, engine, engine_kwargs, **kwargs)\u001b[0m\n\u001b[0;32m  10360\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapply\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m frame_apply\n\u001b[0;32m  10362\u001b[0m op \u001b[38;5;241m=\u001b[39m frame_apply(\n\u001b[0;32m  10363\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m  10364\u001b[0m     func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m  10372\u001b[0m     kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[0;32m  10373\u001b[0m )\n\u001b[1;32m> 10374\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapply\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32me:\\Eshwar\\Projects\\Home Battery\\.venv\\Lib\\site-packages\\pandas\\core\\apply.py:916\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    913\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw:\n\u001b[0;32m    914\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_raw(engine\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine, engine_kwargs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine_kwargs)\n\u001b[1;32m--> 916\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32me:\\Eshwar\\Projects\\Home Battery\\.venv\\Lib\\site-packages\\pandas\\core\\apply.py:1063\u001b[0m, in \u001b[0;36mFrameApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1061\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mapply_standard\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m   1062\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpython\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m-> 1063\u001b[0m         results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_series_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1064\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1065\u001b[0m         results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_series_numba()\n",
      "File \u001b[1;32me:\\Eshwar\\Projects\\Home Battery\\.venv\\Lib\\site-packages\\pandas\\core\\apply.py:1081\u001b[0m, in \u001b[0;36mFrameApply.apply_series_generator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1078\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m option_context(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode.chained_assignment\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m   1079\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(series_gen):\n\u001b[0;32m   1080\u001b[0m         \u001b[38;5;66;03m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[1;32m-> 1081\u001b[0m         results[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1082\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[0;32m   1083\u001b[0m             \u001b[38;5;66;03m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[0;32m   1084\u001b[0m             \u001b[38;5;66;03m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[0;32m   1085\u001b[0m             results[i] \u001b[38;5;241m=\u001b[39m results[i]\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn[27], line 24\u001b[0m, in \u001b[0;36mget_rate_sale\u001b[1;34m(row)\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m interval_start \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m valid_from:\n\u001b[0;32m     23\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m price_row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalue_inc_vat\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m---> 24\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[43mvalid_from\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m<\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43minterval_start\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m<\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mvalid_to\u001b[49m:\n\u001b[0;32m     25\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m price_row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalue_inc_vat\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: '<=' not supported between instances of 'Timestamp' and 'str'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def get_rate(row):\n",
    "    interval_start = row['interval_start']\n",
    "    for _, price_row in price_df.iterrows():\n",
    "        valid_from = price_row['valid_from']\n",
    "        valid_to = price_row['valid_to']\n",
    "\n",
    "        if pd.isna(valid_to):  # Use pd.isna() to reliably check for NaT (Not a Time)\n",
    "            if interval_start >= valid_from:\n",
    "                return price_row['value_inc_vat']\n",
    "        elif valid_from <= interval_start < valid_to:\n",
    "            return price_row['value_inc_vat']\n",
    "    return None  # Return None if no matching rate is found\n",
    "\n",
    "\n",
    "price_df = merged_tariffs[merged_tariffs['source_file']\n",
    "                          == 'E-1R-INTELLI-VAR-22-10-14-H']\n",
    "power_df = merged_kWh.copy()\n",
    "\n",
    "power_df['rate'] = power_df.apply(get_rate, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export price merge with main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Eshwar\\AppData\\Local\\Temp\\ipykernel_2852\\10181034.py:20: FutureWarning: In a future version of pandas, parsing datetimes with mixed time zones will raise an error unless `utc=True`. Please specify `utc=True` to opt in to the new behaviour and silence this warning. To create a `Series` with mixed offsets and `object` dtype, please use `apply` and `datetime.datetime.strptime`\n",
      "  power_df['interval_end'] = pd.to_datetime(power_df['interval_end'])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def get_rate_sale(row):\n",
    "    interval_start = row['interval_start']\n",
    "    for _, price_row in export_df.iterrows():\n",
    "        valid_from = price_row['valid_from']\n",
    "        valid_to = price_row['valid_to']\n",
    "\n",
    "        if pd.isna(valid_to):  # Use pd.isna() to reliably check for NaT (Not a Time)\n",
    "            if interval_start >= valid_from:\n",
    "                return price_row['value_inc_vat']\n",
    "        elif valid_from <= interval_start < valid_to:\n",
    "            return price_row['value_inc_vat']\n",
    "    return None  # Return None if no matching rate is found\n",
    "\n",
    "\n",
    "export_df = pd.read_csv('export.csv', parse_dates=True)\n",
    "export_df['valid_from'] = pd.to_datetime(export_df['valid_from'], utc=True)\n",
    "export_df['valid_to'] = pd.to_datetime(export_df['valid_to'], utc=True)\n",
    "power_df['interval_start'] = pd.to_datetime(\n",
    "    power_df['interval_start'], utc=True)\n",
    "power_df['interval_end'] = pd.to_datetime(power_df['interval_end'], utc=True)\n",
    "power_df['rate_sale'] = power_df.apply(get_rate_sale, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "power_df = pd.read_csv('power.csv', parse_dates=True)\n",
    "export_df = pd.read_csv('export.csv', parse_dates=True)\n",
    "export_df['valid_from'] = pd.to_datetime(export_df['valid_from'], utc=True)\n",
    "export_df['valid_to'] = pd.to_datetime(export_df['valid_to'], utc=True)\n",
    "power_df['interval_start'] = pd.to_datetime(\n",
    "    power_df['interval_start'], utc=True)\n",
    "power_df['interval_end'] = pd.to_datetime(power_df['interval_end'], utc=True)\n",
    "# Ensure 'valid_from' is the index in export_df for efficient lookup\n",
    "export_df = export_df.sort_values('valid_from').set_index('valid_from')\n",
    "\n",
    "# Use merge_asof to find the matching rate for each interval_start\n",
    "power_df = pd.merge_asof(\n",
    "    power_df.sort_values('interval_start'),  # Sort power_df for merge_asof\n",
    "    # Select only necessary column from export_df\n",
    "    export_df[['value_inc_vat']],\n",
    "    left_on='interval_start',\n",
    "    # Merge on the index of export_df (valid_from)\n",
    "    right_index=True,\n",
    "    # Find the latest valid_from <= interval_start\n",
    "    direction='backward',\n",
    "    # You can use a large time delta to match any valid_from if valid_to is missing\n",
    "    tolerance=pd.Timedelta('100000D'),\n",
    "    allow_exact_matches=True                # Allow exact matches on 'valid_from'\n",
    ").rename(columns={'value_inc_vat': 'rate_sale'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Data output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# power_df.drop(columns=['source_file'], inplace=True)\n",
    "power_df.to_csv('historic_data.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
